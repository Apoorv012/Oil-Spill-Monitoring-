# -*- coding: utf-8 -*-
"""Copy of FINAL OIL SPILL

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MOPQdjIHKLKoPAP59DepfRvnztAHRBPe
"""

pip install keras-layer-normalization

import numpy as np
import os
import cv2
import matplotlib.pyplot as plt
import random
import pickle
import seaborn as sns
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential, load_model

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator
from keras.preprocessing import image
from tensorflow.keras.layers import BatchNormalization
import matplotlib.pyplot as plt
import seaborn as sns
sns.set_style('whitegrid')

from google.colab import drive
drive.mount('/content/drive')

!pip install opencv-python

"""## Read dataset and convert into images and labels"""

DIRECTORY = r'/content/drive/MyDrive/Oil Spill CNN/Oil spill '
CATEGORIES = ['no oil spill', 'oil spill']

data = []

for category in CATEGORIES:
    path = os.path.join(DIRECTORY, category)
    for img in os.listdir(path):
        img_path = os.path.join(path, img)
        label = CATEGORIES.index(category)
        try:
          arr = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
          new_arr = cv2.resize(arr, (60, 60))
          data.append([new_arr, label])
        except:
          break

len(data)

random.shuffle(data)

X = []
y = []
for features, label in data:
    X.append(features)
    y.append(label)

X = np.array(X)
y = np.array(y)

X

pickle.dump(X, open('X.pkl', 'wb'))
pickle.dump(y, open('y.pkl', 'wb'))

"""## Exploratory Data Analysis"""

# to display grid of images
rows = 4
cols = 4
axes = []

fig = plt.figure(figsize=(10,10))
for i in range(rows * cols):
    axes.append( fig.add_subplot(rows, cols, i+1) )
    plt.imshow(cv2.cvtColor(X[i], cv2.COLOR_BGR2RGB))

sns.countplot(y)

"""## Scaling images from (0 - 255) to (0-1) """

X = X/255

X

"""## Use of appropriate shape as input"""

X.shape

X = X.reshape(-1, 60, 60, 1)

X.shape

datagen = ImageDataGenerator(
        featurewise_center=False,  # set input mean to 0 over the dataset
        samplewise_center=False,  # set each sample mean to 0
        featurewise_std_normalization=False,  # divide inputs by std of the dataset
        samplewise_std_normalization=False,  # divide each input by its std
        zca_whitening=False,  # apply ZCA whitening
        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)
        zoom_range = 0.2, # Randomly zoom image 
        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
        horizontal_flip = True,  # randomly flip images
        vertical_flip=False)  # randomly flip images

datagen.flow(X, y, batch_size=32)

"""## Model Building"""

from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten

model = Sequential()

model.add(Conv2D(64, (3,3), activation = 'relu'))
model.add(MaxPooling2D((2,2)))

model.add(Conv2D(64, (3,3), activation = 'relu'))
model.add(MaxPooling2D((2,2)))

model.add(Flatten())

model.add(Dense(128, input_shape = X.shape[1:], activation = 'relu'))

model.add(Dense(2, activation = 'softmax'))

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

"""## Model Training"""

history = model.fit(X, y, epochs=20, validation_split=0.2)

loss_train = history.history['loss']
loss_val = history.history['val_loss']
epochs = range(1,21)
plt.plot(epochs, loss_train, 'g', label='Training loss')
plt.plot(epochs, loss_val, 'b', label='validation loss')
plt.title('Training and Validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

model.save("model-0.52.h5")

"""## Use Model on test image"""

def image(path):
    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    new_arr = cv2.resize(img, (60, 60))
    new_arr = np.array(new_arr)
    new_arr = new_arr.reshape(-1, 60, 60, 1)
    return new_arr

prediction = model.predict([image('/content/drive/MyDrive/Oil Spill CNN/OIL SPILL/val/oil spill/oil_spill_23.jpg')])
print(CATEGORIES[prediction.argmax()])